{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What would be the ideal way to do this?\n",
    "\n",
    "1. Define points $x_0,\\dots,x_{n-1}$ (arbitrary) and pick some $\\varepsilon$\n",
    "2. Define the $\\varepsilon$ graph. That is the graph where $i-j$ connect if $D[i,j] \\leq \\varepsilon$\n",
    "3. Define the VR complex at $\\varepsilon$. Every complete subgraph becomes a simplex. This is where we wonder if enumerating all simplices creates duplicates\n",
    "\n",
    "Idea: Only generate simplices with increasing vertex order.\n",
    "$$N^+(i) = \\{\\, j>i : D[i,j]\\leq \\varepsilon \\,\\}$$\n",
    "I.e. neighbors that come after me.\n",
    "\n",
    "4. Now we have a simplex $\\sigma = [i_0<i_1<\\dots<i_k]$. We want to add a new vertex $n$ to make the simplex larger. For $\\sigma \\cup \\{n\\}$ to be a simplex, $n$ must connect to every vertex in $\\sigma$ in the $\\varepsilon$ graph. \n",
    "\n",
    "$$n \\in N^+(i_0)\\cap N^+(i_1)\\cap \\cdots \\cap N^+(i_k)$$\n",
    "\n",
    "This is why we should maintain a candidate set $C(\\sigma) = N^+(i_0)\\cap N^+(i_1)\\cap \\cdots \\cap N^+(i_k)$. Now we start at vertex $i$ and find $C([i]) = N^+(i)$. If we extend by adding n, the new candidates become $C(\\sigma \\cup \\{n\\}) = C(\\sigma)\\cap N^+(n)$.\n",
    "\n",
    "This guarantees that only vertices that connect to all simplex vertices are considered and they respect ordering.\n",
    "\n",
    "5. If we were to compute all edges, then all triangles, ..., we would store too many simplices. We want to build one simplex at a time, emit its contribution as soon as possible, then backtrack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does Dlotko do compared to this?\n",
    "\n",
    "1. We already define points in an ascending arbitrary manner with this.\n",
    "```python\n",
    "def pairwise_dist(X: np.ndarray) -> np.ndarray: #input is a shape X with n points and d dim\n",
    "    diff = X[:, None, :] - X[None, :, :] #diff is every pairwise distance vector\n",
    "    return np.linalg.norm(diff, axis=2)\n",
    "\n",
    "def subseq_neighbors(D: np.ndarray, i: int, epsilon: float) -> list[int]:\n",
    "    n = D.shape[0] #precomputed distance matrix D (n is number of points)\n",
    "    js = np.where((D[i] <= epsilon) & (np.arange(n) > i))[0]\n",
    "    return js.tolist()\n",
    "```\n",
    "subseq_neighbors returns the neighbor set of a vertex with only indices larger than itself ($N^+(i) = \\{\\, j > i \\mid D[i,j] \\leq \\varepsilon \\,\\}$). This is how we enforce ordering and avoid duplicate simplices. Let's analyze the line `js = np.where((D[i] <= epsilon) & (np.arange(n) > i))[0]`. `D[i] <= epsilon` is taking the ith row of the distance matrix produces a boolean array containing True is point j is withing $\\varepsilon$ of i. `np.arange(n) > 1` creates $[0,1, \\dots, n-1]$ and produces a boolean list of True if the indice in greater than i. Now we take the and of these two state ments so we have a boolean list that says True if the point is within $\\varepsilon$ distance and its index is $> i$. `np.where` returns the indices where the condition is True, so js is an array of valid neighbors of vertex $i$. \n",
    "\n",
    "pairwise_dist takes in a shape $X$ and outputs its symmetric distance matrix $D[i,j] = \\|X[i] - X[j]\\|$. We can have some issues here with large VR. If $n=10,000$, then $D$ contains 100,000,000 entries. Potentially think about avoiding storing the full distance matrix. \n",
    "\n",
    "2. Looking at Algorithm 1\n",
    "\n",
    "Abstractly what we want to do is:\n",
    "\n",
    "```python\n",
    "for each i:\n",
    "    expand([i], 0, N+(i))\n",
    "```\n",
    "\n",
    "We currently have:\n",
    "\n",
    "```python\n",
    "for i in range(n):\n",
    "    simplices = [[i]] #this is a list of a list just like a simplex is a set of a set (this is initializing our simplex)\n",
    "    filtrations = [0]\n",
    "    common_subseq_neighs = subseq_neighbors(D, i, epsilon) #this is C = N+(i)\n",
    "```\n",
    "These two are identical.\n",
    "\n",
    "\n",
    "Now we want to `emit(fsigma, (-1)^dim)` and we have:\n",
    "\n",
    "```python\n",
    "for sigma, f_sigma in zip(simplices, filtrations):\n",
    "    dim_sigma = len(sigma) - 1\n",
    "    sign = 1 if (dim_sigma % 2 == 0) else -1 #this is for EC assigns its sign in the alternating sum\n",
    "    C.append((f_sigma, sign)) #stores a pair (filtration value, +-1)\n",
    "```\n",
    "\n",
    "Now we wish to grow the simplex. \n",
    "\n",
    "Ideally:\n",
    "```python\n",
    "for n in C:\n",
    "    f_new = max(fsigma, max_{v in sigma} D[v,n])\n",
    "    C_new = C intersect N+(n)\n",
    "```\n",
    "We have:\n",
    "```python\n",
    "for sigma, f_sigma, commonN in zip(simplices, filtrations, common_subseq_neighs):\n",
    "    for n in commonN:\n",
    "        sigma2 = sigma + [n]\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
